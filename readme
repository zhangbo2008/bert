这个文件用来记录bert运行过程中遇到的问题.

首先运行createnpretaining_data.py这个文件

里面需要vocab.txt这个文件.
发现没有,网上说只需要下载pre_train_model里面有.

我下载的chinese_L-12_H-768_A-12.zip
然后解压到同一个bert目录总.


vocab.txt readme.md里面说他是word----id 的文件.所以要用给的模型里面的官方编码,才能对应官方的
model文件.

看了一下vocab.txt里面的文字都很乱..很迷

不管了,直接参数写上,然后开始debug学习.


注意跟进requiremnte 里面写的版本需要的是1.11


squad 解释:
Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.




http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E7%94%B5%E5%BD%B1%E8%AF%84%E8%AE%BA%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90

这个很重要
https://mp.weixin.qq.com/s/qnsvDQvPZSJG6rDtbFGggA


Sota值:就是state of the art 世界第一.

确实代码跑多了,没意思,应该去翻翻书,补基础了.确实需要看懂em算法.好像是最大熵.
是最大期望,在李航的书上写了.


dropout层的使用:
https://www.zhihu.com/question/61751133?sort=created



2019-10-14,11点43

bert:本质是完形填空,填对了就损失0,错了就负1万,非监督.所以可以随便finetune


使用bert:使用test1.py来测试movie 情感分类.











